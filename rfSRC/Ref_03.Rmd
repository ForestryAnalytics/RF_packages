rfsrc.news Show the NEWS file
Description
Show the NEWS file of the randomForestSRC package.
Usage
rfsrc.news(...)
Arguments
... Further arguments passed to or from other methods.
rfsrcFast 61
Value
None.
Author(s)
Hemant Ishwaran and Udaya B. Kogalur
rfsrcFast Fast Random Forests
Description
Fast approximate random forests using subsampling with forest options set to encourage computational
speed. Applies to all families.
Usage
## S3 method for class 'rfsrc'
rfsrcFast(formula, data,
ntree = 500,
nsplit = 10,
bootstrap = "by.root",
ensemble = "oob",
sampsize = function(x){min(x * .632, max(150, sqrt(x)))},
samptype = "swor",
samp = NULL,
ntime = 50,
forest = FALSE,
...)
Arguments
formula A symbolic description of the model to be fit. If missing, unsupervised splitting
is implemented.
data Data frame containing the y-outcome and x-variables.
ntree Number of trees.
nsplit Non-negative integer value specifying number of random split points used to
split a node (deterministic splitting corresponds to the value zero and is much
slower).
bootstrap Bootstrap protocol used in growing a tree.
ensemble Specifies the type of ensemble. We request only out-of-sample which corresponds
to "oob".
sampsize Function specifying requested size of subsampled data relative to the original
data. The requested sample size can also be passed in as a number.
samptype Type of bootstrap used.
62 rfsrcFast
samp Bootstrap specification when "by.user" is used.
ntime Integer value used for survival to constrain ensemble calculations to a grid of
ntime time points.
forest Should the forest object be returned?
... Further arguments to be passed to rfsrc.
Details
Calls rfsrc under various options (including subsampling) to encourage computational speeds.
This will provide a good approximation but will not be as good as default settings of rfsrc.
Value
An object of class (rfsrc, grow).
Author(s)
Hemant Ishwaran and Udaya B. Kogalur
See Also
rfsrc
Examples
## ------------------------------------------------------------
## Iowa housing regression example
## ------------------------------------------------------------
## load the Iowa housing data
data(housing, package = "randomForestSRC")
## do quick and *dirty* imputation
housing2 <- impute(SalePrice ~ ., housing,
ntree = 50, nimpute = 1, splitrule = "random")
## grow a fast forest
o1 <- rfsrcFast(SalePrice ~ ., housing2)
o2 <- rfsrcFast(SalePrice ~ ., housing2, nodesize = 1)
print(o1)
print(o2)
## grow a fast bivariate forest
o3 <- rfsrcFast(cbind(SalePrice,Overall.Qual) ~ ., housing2)
print(o3)
## ------------------------------------------------------------
## White wine classification example
## ------------------------------------------------------------
rfsrcSyn 63
data(wine, package = "randomForestSRC")
wine$quality <- factor(wine$quality)
o <- rfsrcFast(quality ~ ., wine)
print(o)
## ------------------------------------------------------------
## pbc survival example
## ------------------------------------------------------------
data(pbc, package = "randomForestSRC")
o <- rfsrcFast(Surv(days, status) ~ ., pbc)
print(o)
## ------------------------------------------------------------
## WIHS competing risk example
## ------------------------------------------------------------
data(wihs, package = "randomForestSRC")
o <- rfsrcFast(Surv(time, status) ~ ., wihs)
print(o)
rfsrcSyn Synthetic Random Forests
Description
Grows a synthetic random forest (RF) using RF machines as synthetic features. Applies only to
regression and classification settings.
Usage
## S3 method for class 'rfsrc'
rfsrcSyn(formula, data, object, newdata,
ntree = 1000, mtry = NULL, nodesize = 5, nsplit = 10,
mtrySeq = NULL, nodesizeSeq = c(1:10,20,30,50,100),
min.node = 3,
fast = TRUE,
use.org.features = TRUE,
na.action = c("na.omit", "na.impute"),
oob = TRUE,
verbose = TRUE,
...)
Arguments
formula A symbolic description of the model to be fit. Must be specified unless object
is given.
64 rfsrcSyn
data Data frame containing the y-outcome and x-variables in the model. Must be
specified unless object is given.
object An object of class (rfsrc, synthetic). Not required when formula and data
are supplied.
newdata Test data used for prediction (optional).
ntree Number of trees.
mtry mtry value for over-arching synthetic forest.
nodesize Nodesize value for over-arching synthetic forest.
nsplit nsplit-randomized splitting for significantly increased speed.
mtrySeq Sequence of mtry values used for fitting the collection of RF machines. If NULL,
set to the default value p/3.
nodesizeSeq Sequence of nodesize values used for the fitting the collection of RF machines.
min.node Minimum forest averaged number of nodes a RF machine must exceed in order
to be used as a synthetic feature.
fast Use fast random forests, rfsrcFast, in place of rfsrc? Improves speed but
may be less accurate.
use.org.features
In addition to synthetic features, should the original features be used when fitting
synthetic forests?
na.action Missing value action. The default na.omit removes the entire record if even
one of its entries is NA. The action na.impute pre-imputes the data using fast
imputation via impute.rfsrc.
oob Preserve "out-of-bagness" so that error rates and VIMP are honest? Default is
yes (‘oob=TRUE’).
verbose Set to TRUE for verbose output.
... Further arguments to be passed to the rfsrc function used for fitting the synthetic
forest.
Details
A collection of random forests are fit using different nodesize values. The predicted values from
these machines are then used as synthetic features (called RF machines) to fit a synthetic random
forest (the original features are also used in constructing the synthetic forest). Currently only implemented
for regression and classification settings (univariate and multivariate).
Synthetic features are calculated using out-of-bag (OOB) data to avoid over-using training data.
However, to guarantee that performance values such as error rates and VIMP are honest, bootstrap
draws are fixed across all trees used in the construction of the synthetic forest and its synthetic
features. The option ‘oob=TRUE’ ensures that this happens. Change this option at your own peril.
If values for mtrySeq are given, RF machines are constructed for each combination of nodesize and
mtry values specified by nodesizeSeq mtrySeq.
rfsrcSyn 65
Value
A list with the following components:
rfMachines RF machines used to construct the synthetic features.
rfSyn The (grow) synthetic RF built over training data.
rfSynPred The predict synthetic RF built over test data (if available).
synthetic List containing the synthetic features.
opt.machine Optimal machine: RF machine with smallest OOB error rate.
Author(s)
Hemant Ishwaran and Udaya B. Kogalur
References
Ishwaran H. and Malley J.D. (2014). Synthetic learning machines. BioData Mining, 7:28.
See Also
rfsrc, rfsrcFast
Examples
## ------------------------------------------------------------
## compare synthetic forests to regular forest (classification)
## ------------------------------------------------------------
## rfsrc and rfsrcSyn calls
if (library("mlbench", logical.return = TRUE)) {
## simulate the data
ring <- data.frame(mlbench.ringnorm(250, 20))
## classification forests
ringRF <- rfsrc(classes ~., ring)
## synthetic forests
## 1 = nodesize varied
## 2 = nodesize/mtry varied
ringSyn1 <- rfsrcSyn(classes ~., ring)
ringSyn2 <- rfsrcSyn(classes ~., ring, mtrySeq = c(1, 10, 20))
## test-set performance
ring.test <- data.frame(mlbench.ringnorm(500, 20))
pred.ringRF <- predict(ringRF, newdata = ring.test)
pred.ringSyn1 <- rfsrcSyn(object = ringSyn1, newdata = ring.test)$rfSynPred
pred.ringSyn2 <- rfsrcSyn(object = ringSyn2, newdata = ring.test)$rfSynPred
66 stat.split
print(pred.ringRF)
print(pred.ringSyn1)
print(pred.ringSyn2)
}
## ------------------------------------------------------------
## compare synthetic forest to regular forest (regression)
## ------------------------------------------------------------
## simulate the data
n <- 250
ntest <- 1000
N <- n + ntest
d <- 50
std <- 0.1
x <- matrix(runif(N * d, -1, 1), ncol = d)
y <- 1 * (x[,1] + x[,4]^3 + x[,9] + sin(x[,12]*x[,18]) + rnorm(n, sd = std)>.38)
dat <- data.frame(x = x, y = y)
test <- (n+1):N
## regression forests
regF <- rfsrc(y ~ ., dat[-test, ], )
pred.regF <- predict(regF, dat[test, ], importance = "none")
## synthetic forests using fast rfsrc
synF1 <- rfsrcSyn(y ~ ., dat[-test, ], fast = TRUE, newdata = dat[test, ])
synF2 <- rfsrcSyn(y ~ ., dat[-test, ], fast = TRUE,
newdata = dat[test, ], mtrySeq = c(1, 10, 20, 30, 40, 50))
## standardized MSE performance
mse <- c(tail(pred.regF$err.rate, 1),
tail(synF1$rfSynPred$err.rate, 1),
tail(synF2$rfSynPred$err.rate, 1)) / var(y[-test])
names(mse) <- c("forest", "synthetic1", "synthetic2")
print(mse)
## ------------------------------------------------------------
## multivariate synthetic forests
## ------------------------------------------------------------
mtcars.new <- mtcars
mtcars.new$cyl <- factor(mtcars.new$cyl)
mtcars.new$carb <- factor(mtcars.new$carb, ordered = TRUE)
trn <- sample(1:nrow(mtcars.new), nrow(mtcars.new)/2)
mvSyn <- rfsrcSyn(cbind(carb, mpg, cyl) ~., mtcars.new[trn,])
mvSyn.pred <- rfsrcSyn(object = mvSyn, newdata = mtcars.new[-trn,])
stat.split Acquire Split Statistic Information
stat.split 67
Description
Extract split statistic information from the forest. The function returns a list of length ntree, in
which each element corresponds to a tree. The element [[b]] is itself a vector of length xvar.names
identified by its x-variable name. Each element [[b]]$xvar contains the complete list of splits on
xvar with associated identifying information. The information is as follows:
1. treeID Tree identifier.
2. nodeID Node identifier.
3. parmID Variable indentifier.
4. contPT Value node was split in the case of a continuous variable.
5. mwcpSZ Size of the multi-word complementary pair in the case of a factor split.
6. dpthID Zero (0) based depth of split.
7. spltTY Split type for parent node:
bit 1 bit 0 meaning
—– —– ——-
0 0 0 = both daughters have valid splits
0 1 1 = only the right daughter is terminal
1 0 2 = only the left daughter is terminal
1 1 3 = both daughters are terminal
8. spltEC End cut statistic for real valued variables between [0,0.5] that is small when the split
is towards the edge and large when the split is towards the middle. Subtracting this value
from 0.5 yields the end cut statistic studied in Ishwaran (2014) and is a way to identify ECP
behavior (end cut preference behavior).
9. spltST Split statistic:
(a) For objects of class (rfsrc, grow), this is the split statistic that resulted in the variable
being choosen for the split.
(b) For an object of class (rfsrc, pred) this is the variance of the response within the node for
the test data. This value is relevant only for real valued responses. In classification and
survival, it is not relevant.
Usage
## S3 method for class 'rfsrc'
stat.split(object, ...)
Arguments
object An object of class (rfsrc, grow), (rfsrc, synthetic) or (rfsrc, predict)
... Further arguments passed to or from other methods.
Value
Invisibly, a list with the following components:
68 subsample
... ...
Author(s)
Hemant Ishwaran and Udaya B. Kogalur
References
Ishwaran H. (2015). The effect of splitting on random forests. Machine Learning, 99:75-118.
Examples
## run a forest, then make a call to stat.split
grow.obj <- rfsrc(mpg ~., data = mtcars, membership=TRUE, statistics=TRUE)
stat.obj <- stat.split(grow.obj)
## nice wrapper to extract split-statistic for desired variable
## for continuous variables plots ECP data
get.split <- function(splitObj, xvar, inches = 0.1, ...) {
which.var <- which(names(splitObj[[1]]) == xvar)
ntree <- length(splitObj)
stat <- data.frame(do.call(rbind, sapply(1:ntree, function(b) {
splitObj[[b]][which.var]})))
dpth <- stat$dpthID
ecp <- 1/2 - stat$spltEC
sp <- stat$contPT
if (!all(is.na(sp))) {
fgC <- function(x) {
as.numeric(as.character(cut(x, breaks = c(-1, 0.2, 0.35, 0.5),
labels = c(1, 4, 2))))
}
symbols(jitter(sp), jitter(dpth), ecp, inches = inches, bg = fgC(ecp),
xlab = xvar, ylab = "node depth", ...)
legend("topleft", legend = c("low ecp", "med ecp", "high ecp"),
fill = c(1, 4, 2))
}
invisible(stat)
}
## use get.split to investigate ECP behavior of variables
