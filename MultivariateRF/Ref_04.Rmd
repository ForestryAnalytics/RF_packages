single_tree_prediction
Prediction of Testing Samples for single tree
#### Description
Predicts the output responses of testing samples based on the input regression tree

#### Usage
single_tree_prediction(Single_Model, X_test, Variable_number)

#### Arguments
Single_Model Random Forest or Multivariate Random Forest Model of a particular tree
X_test Testing samples of size Q x N, Q is the number of testing samples and N is the
number of features (same order and size used as training)
Variable_number
Number of Output Features

#### Details
A regression tree model contains splitting criteria for all the splits in the tree and output responses
of training samples in the leaf nodes. A testing sample using these criteria will reach a leaf node
and the average of the Output response vectors in the leaf node is considered as the prediction of
the testing sample.
Value
Prediction result of the Testing samples for a particular tree

## splitt2 Split of the Parent node
Description
Split of the training samples of the parent node into the child nodes based on the feature and threshold
that produces the minimum cost
#### Usage

splitt2(X, Y, m_feature, Index, Inv_Cov_Y, Command, ff)
splitt2 9

#### Arguments
X Input Training matrix of size M x N, M is the number of training samples and N
is the number of features
Y Output Training response of size M x T, M is the number of samples and T is
the number of output responses
m_feature Number of randomly selected features considered for a split in each regression
tree node.
Index Index of training samples
Inv_Cov_Y Inverse of Covariance matrix of Output Response matrix for MRF (Input [0 0; 0
0] for RF)
Command 1 for univariate Regression Tree (corresponding to RF) and 2 for Multivariate
Regression Tree (corresponding to MRF)
ff Vector of m_feature from all features of X. This varies with each split

#### Details

At each node of a regression a tree, a fixed number of features (m_feature) are selected randomly
to be considered for generating the split. Node cost for all selected features along with possible n-1
thresholds for n samples are considered to select the feature and threshold with minimum cost.

#### Value
List with the following components:
* index_left Index of the samples that are in the left node after splitting
* index_right Index of the samples that are in the right node after splitting
* which_feature The number of the feature that produces the minimum splitting cost
* threshold_feature The threshold value for the node split. A feature value less than or equal to the
threshold will go to the left node and it will go to the right node otherwise.

Examples

library(MultivariateRandomForest)
X=matrix(runif(20*100),20,100)
Y=matrix(runif(20*3),20,3)
m_feature=5
Index=1:20
Inv_Cov_Y=solve(cov(Y))
ff2 = ncol(X) # number of features
ff =sort(sample(ff2, m_feature))
Command=2#MRF, as number of output feature is greater than 1
Split_criteria=splitt2(X,Y,m_feature,Index,Inv_Cov_Y,Command,ff)
10 split_node
